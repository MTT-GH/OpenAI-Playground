{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6fbc28d",
   "metadata": {},
   "source": [
    "# Code analysis with Langchain + Azure OpenAI + Azure Cognitive Search (vector store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d42d4f",
   "metadata": {},
   "source": [
    "The following demo will show how to analyze your existing by using both Azure OpenAI and Search with the help of Langchain.\n",
    "\n",
    "**LangChain** is an open-source framework that simplifies the creation of applications using large language models (LLMs). It provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. You can use it to connect a language model to other sources of data, and allow it to interact with its environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "#from dotenv import load_dotenv\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.retrievers import AzureCognitiveSearchRetriever\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efcce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0e03c7",
   "metadata": {},
   "source": [
    "## Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d955202",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls notebooks/*.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57259314",
   "metadata": {},
   "source": [
    "Analyze the 3 example notebooks for customized code analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee38c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"notebooks\"\n",
    "\n",
    "# Loop through the folders\n",
    "docs = []\n",
    "for dirpath, dirnames, filenames in os.walk(root_dir):\n",
    "    for file in filenames:\n",
    "        print(file)\n",
    "        try:\n",
    "            loader = TextLoader(os.path.join(dirpath, file), encoding=\"utf-8\")\n",
    "            docs.extend(loader.load_and_split())\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fe2ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunk of texts\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7730310",
   "metadata": {},
   "source": [
    "We are going to load the settings from GitHub Codespace secrets instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ebca75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_dotenv(\"azure.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbaab8c",
   "metadata": {},
   "source": [
    "**Make sure this settings exist on your GitHub repository Codespace secrets!**\n",
    "\n",
    "\n",
    "In my case both the model and deployment are named \"text-embedding-ada-002\"\n",
    "\n",
    ">NOTE: it takes a few minutes to add the document embeddings to search (7 minutes for me)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5780c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize our embedding model\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    deployment=os.getenv(\"OPENAI_ADA_EMBEDDING_DEPLOYMENT_NAME\"),\n",
    "    model=os.getenv(\"OPENAI_ADA_EMBEDDING_MODEL_NAME\"),\n",
    "    openai_api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), \n",
    "    openai_api_type=\"azure\",\n",
    "    chunk_size=1,\n",
    ")\n",
    "\n",
    "index_name = \"index-pythonnotebooks\"\n",
    "\n",
    "# Set our Azure Search\n",
    "acs = AzureSearch(\n",
    "    azure_search_endpoint=os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\"),\n",
    "    azure_search_key=os.getenv(\"AZURE_SEARCH_ADMIN_KEY\"),\n",
    "    index_name=index_name,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Add documents to Azure Search\n",
    "acs.add_documents(documents=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28afc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\") \n",
    "# Define Azure Cognitive Search as our retriever\n",
    "retriever = AzureCognitiveSearchRetriever(\n",
    "    content_key=\"content\", top_k=10, index_name=index_name, api_key=api_key\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950629e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set chatGPT 3.5 as our LLM\n",
    "llm = AzureChatOpenAI(deployment_name=os.getenv(\"AZURE_OPENAI_MODEL_CHAT\"), temperature=0.7, max_tokens=100, \n",
    "        openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"), \n",
    "        openai_api_base=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        openai_api_version=os.getenv(\"AZURE_OPENAI_MODEL_CHAT_VERSION\"),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b72fa19",
   "metadata": {},
   "source": [
    "Commented not to expose settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774a642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7fd5b7",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2848f354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a template message\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "You are a python expert and you should demonstrate some python knowledge.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible. \n",
    "Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n",
    "\n",
    "# Set the Retrieval QA chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT},\n",
    "    return_source_documents=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352e41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Could you explain the notebook 01 Image Analysis.ipynb\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    # chat_history.append((question, result))\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(\n",
    "        f\"Source: {json.loads(result['source_documents'][0].metadata['metadata'])['source']} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab78382",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How to get image captions? Show me a python code\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    # chat_history.append((question, result))\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(\n",
    "        f\"Source: {json.loads(result['source_documents'][0].metadata['metadata'])['source']} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06306631",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"Explain the notebook 03 Background removal.ipynb\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    # chat_history.append((question, result))\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(\n",
    "        f\"Source: {json.loads(result['source_documents'][0].metadata['metadata'])['source']} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6d5ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How to remove background from an image using Azure AI?\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    # chat_history.append((question, result))\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(\n",
    "        f\"Source: {json.loads(result['source_documents'][0].metadata['metadata'])['source']} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8f13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\"How to get image captions?\"]\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "for question in questions:\n",
    "    result = qa_chain({\"query\": question, \"chat_history\": chat_history})\n",
    "    # chat_history.append((question, result))\n",
    "    print(f\"Question: {question} \\n\")\n",
    "    print(f\"Answer: {result['result']} \\n\")\n",
    "    print(\n",
    "        f\"Source: {json.loads(result['source_documents'][0].metadata['metadata'])['source']} \\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ac033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
