{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "492978dd",
   "metadata": {},
   "source": [
    "# Azure Open AI - Demo 4 Speech summarizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7499e54",
   "metadata": {},
   "source": [
    "**Before getting started!**\n",
    "- Create an Azure Speech service and create GitHub Secrets for it (or use and .env file uncommenting some sections)\n",
    "    - AZURE_SPEECH_KEY and AZURE_SPEECH_REGION\n",
    "- Make sure speech module **azure-cognitiveservices-speech** is installed (already executed automatically in the GH Codespace from requirements.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2a507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1c20fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf8f023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"openai version =\", openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad052b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dotenv(\"azure.env\")\n",
    "\n",
    "openai.api_type: str = \"azure\"\n",
    "# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "# openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_MODEL_CHAT_VERSION\")\n",
    "\n",
    "openai.engine = os.getenv(\"AZURE_OPENAI_MODEL_CHAT\")\n",
    "\n",
    "azure_speech_key = os.getenv(\"AZURE_SPEECH_KEY\")\n",
    "azure_speech_region = os.getenv(\"AZURE_SPEECH_REGION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e2987d",
   "metadata": {},
   "source": [
    "## 1. Convert Audio To Text Using Azure Speech To Text  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d881dae1",
   "metadata": {},
   "source": [
    "Recognize feature provided by Azure Speech to convert Audio to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994d6264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_speech_from_file(filename):\n",
    "    \"\"\"This function transcribes an audio file into its corresponding textual output.\"\"\"\n",
    "\n",
    "    # setup global parameters\n",
    "    global done\n",
    "    done = False\n",
    "    global recognized_text_list\n",
    "    recognized_text_list = []\n",
    "\n",
    "    # initiate the Speech Service\n",
    "    speech_config = speechsdk.SpeechConfig(\n",
    "        subscription=azure_speech_key, region=azure_speech_region\n",
    "    )\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=filename)\n",
    "\n",
    "    # create a Speech Recognizer\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(\n",
    "        speech_config=speech_config, audio_config=audio_config\n",
    "    )\n",
    "\n",
    "    # define a call-back stop function\n",
    "    def stop_cb(evt: speechsdk.SessionEventArgs):\n",
    "        \"\"\"callback that signals to stop continuous recognition upon receiving an event `evt`\"\"\"\n",
    "        print(\"CLOSING on {}\".format(evt))\n",
    "        global done\n",
    "        done = True\n",
    "\n",
    "    # define a call-back recognize function\n",
    "    def recognize_cb(evt: speechsdk.SpeechRecognitionEventArgs):\n",
    "        \"\"\"callback for recognizing the recognized text\"\"\"\n",
    "        global recognized_text_list\n",
    "        recognized_text_list.append(evt.result.text)\n",
    "        print(\"RECOGNIZED: {}\".format(evt.result.text))\n",
    "\n",
    "    # connect callbacks to the recognizer events\n",
    "    speech_recognizer.recognized.connect(recognize_cb)\n",
    "    speech_recognizer.session_started.connect(\n",
    "        lambda evt: print(\"STT SESSION STARTED: {}\".format(evt))\n",
    "    )\n",
    "    speech_recognizer.session_stopped.connect(\n",
    "        lambda evt: print(\"STT SESSION STOPPED {}\".format(evt))\n",
    "    )\n",
    "\n",
    "    # stop continuous speech recognition\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "\n",
    "    # start continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    while not done:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "\n",
    "    return recognized_text_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54536842",
   "metadata": {},
   "source": [
    "## 2. Summarize Audio - Positive Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033bf843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play the audio sound\n",
    "Audio(\"documents/good_review.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae6f226",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = recognize_speech_from_file(\"documents/good_review.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7023883e",
   "metadata": {},
   "source": [
    "In our case we will use the GPT3 model used in other demos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"text-davinci-003\"\n",
    "print(\"openai.engine =\", openai.engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2884e",
   "metadata": {},
   "source": [
    "Analyze the provided Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97bbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a prompt for text analytics\n",
    "prompt = f\"\"\"Text:\n",
    "\n",
    "             ###\n",
    "             {\" \".join(text)}\n",
    "             ###\n",
    "             \n",
    "             Tasks:\n",
    "             1. Summarize the above text in a short and concise manner.\n",
    "             2. Determine the above text as whether Positive or Negative.\n",
    "             3. Classify the above text into a topic.\n",
    "             4. Whether the above text is Positive or Negative, \n",
    "                suggest 3 ways to handle it.\n",
    "                \n",
    "             Answer the above 4 tasks, one at a time. \n",
    "          \"\"\"\n",
    "# results = openai.Completion.create(\n",
    "#     engine=model, prompt=prompt, temperature=0, max_tokens=1000\n",
    "# )\n",
    "results = openai.Completion.create(\n",
    "     engine=openai.engine, prompt=prompt, temperature=0, max_tokens=1000\n",
    ")\n",
    "\n",
    "print(results[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23768aad",
   "metadata": {},
   "source": [
    "## 3. Summarize Audio - Negative Example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258fe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(\"documents/bad_review.wav\", autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9282f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = recognize_speech_from_file(\"documents/bad_review.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32a20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Text:\n",
    "\n",
    "             ###\n",
    "             {\" \".join(text)}\n",
    "             ###\n",
    "             \n",
    "             Tasks:\n",
    "             1. Summarize the above text in a short and concise manner.\n",
    "             2. Determine the above text as whether Positive or Negative.\n",
    "             3. Classify the above text into a topic.\n",
    "             4. Whether the above text is Positive or Negative, \n",
    "                suggest 3 ways to handle it.\n",
    "                \n",
    "             Answer the above 4 tasks, one at a time. \n",
    "          \"\"\"\n",
    "\n",
    "# openai results\n",
    "results = openai.Completion.create(\n",
    "    engine=openai.engine, prompt=prompt, temperature=0, max_tokens=1000\n",
    ")\n",
    "\n",
    "print(results[\"choices\"][0][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6bfef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
