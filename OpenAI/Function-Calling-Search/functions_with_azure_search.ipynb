{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function calling with Azure Cognitive Search\n",
    "\n",
    "In this notebook, we'll show how to create a simple chatbot to help you find or create a good recipe. We'll create an index in Azure Cognitive Search using [vector search](), and then use use [function calling]() to write queries to the index.\n",
    "\n",
    "All of the recipes used in this sample were generated by gpt-35-turbo for demo purposes. The recipes are not guaranteed to be safe or taste good so we don't recommend trying them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the preview version of the Azure Cognitive Search Python SDK if you don't have it already\n",
    "# %pip install azure-search-documents --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import json  \n",
    "import openai  \n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config values\n",
    "# with open(r'config.json') as config_file:\n",
    "#     config_details = json.load(config_file)\n",
    "\n",
    "#Load settings from environment variables (GitHub Secrets)\n",
    "    \n",
    "# Configure environment variables for Azure Cognitive Search\n",
    "service_endpoint = os.getenv(\"AZURE_COGNITIVE_SEARCH_SERVICE_NAME\")\n",
    "index_name = \"recipes-index\"\n",
    "key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "credential = AzureKeyCredential(key)\n",
    "\n",
    "# Create the Azure Cognitive Search client to issue queries\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "# Create the index client\n",
    "index_client = SearchIndexClient(endpoint=service_endpoint, credential=credential)\n",
    "\n",
    "# Configure OpenAI environment variables\n",
    "openai.api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "openai.api_base = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    "openai.api_type = \"azure\"  \n",
    "openai.api_version = os.getenv('AZURE_OPENAI_MODEL_CHAT_VERSION')\n",
    "\n",
    "deployment_name = os.getenv('AZURE_OPENAI_MODEL_CHAT') # You need to use the 0613 version of gpt-35-turbo or gpt-4 to work with functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Create the search index and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceRequestError",
     "evalue": "Invalid URL \"ai050-search-unai/indexes('recipes-index')?api-version=2023-07-01-Preview\": No scheme supplied. Perhaps you meant https://ai050-search-unai/indexes('recipes-index')?api-version=2023-07-01-Preview?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mServiceRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Create the search index with the semantic settings\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m index \u001b[39m=\u001b[39m SearchIndex(name\u001b[39m=\u001b[39mindex_name, fields\u001b[39m=\u001b[39mfields, \n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=35'>36</a>\u001b[0m                     vector_search\u001b[39m=\u001b[39mvector_search, semantic_settings\u001b[39m=\u001b[39msemantic_settings)\n\u001b[0;32m---> <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m result \u001b[39m=\u001b[39m index_client\u001b[39m.\u001b[39;49mdelete_index(index)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mindex_name\u001b[39m}\u001b[39;00m\u001b[39m deleted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://codespaces%2Bsolid-halibut-9w75qqp59pg2p9wp/workspaces/OpenAI-Playground/OpenAI/Function-Calling-Search/functions_with_azure_search.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m result \u001b[39m=\u001b[39m index_client\u001b[39m.\u001b[39mcreate_index(index)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/search/documents/indexes/_search_index_client.py:188\u001b[0m, in \u001b[0;36mSearchIndexClient.delete_index\u001b[0;34m(self, index, match_condition, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     index_name \u001b[39m=\u001b[39m index\n\u001b[0;32m--> 188\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49mindexes\u001b[39m.\u001b[39;49mdelete(index_name\u001b[39m=\u001b[39;49mindex_name, error_map\u001b[39m=\u001b[39;49merror_map, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[39m=\u001b[39m settings\u001b[39m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m span_impl_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[39m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mif\u001b[39;00m merge_span \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/search/documents/indexes/_generated/operations/_indexes_operations.py:803\u001b[0m, in \u001b[0;36mIndexesOperations.delete\u001b[0;34m(self, index_name, if_match, if_none_match, request_options, **kwargs)\u001b[0m\n\u001b[1;32m    800\u001b[0m request\u001b[39m.\u001b[39murl \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client\u001b[39m.\u001b[39mformat_url(request\u001b[39m.\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpath_format_arguments)\n\u001b[1;32m    802\u001b[0m _stream \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 803\u001b[0m pipeline_response: PipelineResponse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_pipeline\u001b[39m.\u001b[39;49mrun(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    804\u001b[0m     request, stream\u001b[39m=\u001b[39;49m_stream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    805\u001b[0m )\n\u001b[1;32m    807\u001b[0m response \u001b[39m=\u001b[39m pipeline_response\u001b[39m.\u001b[39mhttp_response\n\u001b[1;32m    809\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m204\u001b[39m, \u001b[39m404\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:230\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m pipeline_request: PipelineRequest[HTTPRequestType] \u001b[39m=\u001b[39m PipelineRequest(request, context)\n\u001b[1;32m    229\u001b[0m first_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_impl_policies \u001b[39melse\u001b[39;00m _TransportRunner(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_transport)\n\u001b[0;32m--> 230\u001b[0m \u001b[39mreturn\u001b[39;00m first_node\u001b[39m.\u001b[39;49msend(pipeline_request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/policies/_redirect.py:197\u001b[0m, in \u001b[0;36mRedirectPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    195\u001b[0m original_domain \u001b[39m=\u001b[39m get_domain(request\u001b[39m.\u001b[39mhttp_request\u001b[39m.\u001b[39murl) \u001b[39mif\u001b[39;00m redirect_settings[\u001b[39m\"\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39mwhile\u001b[39;00m retryable:\n\u001b[0;32m--> 197\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    198\u001b[0m     redirect_location \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_redirect_location(response)\n\u001b[1;32m    199\u001b[0m     \u001b[39mif\u001b[39;00m redirect_location \u001b[39mand\u001b[39;00m redirect_settings[\u001b[39m\"\u001b[39m\u001b[39mallow\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/policies/_retry.py:553\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 is_response_error \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    552\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m    554\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    555\u001b[0m     end_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/policies/_retry.py:531\u001b[0m, in \u001b[0;36mRetryPolicy.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    530\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_timeout(request, absolute_timeout, is_response_error)\n\u001b[0;32m--> 531\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m    532\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_retry(retry_settings, response):\n\u001b[1;32m    533\u001b[0m         retry_active \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincrement(retry_settings, response\u001b[39m=\u001b[39mresponse)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "    \u001b[0;31m[... skipping similar frames: _SansIOHTTPPolicyRunner.send at line 86 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:86\u001b[0m, in \u001b[0;36m_SansIOHTTPPolicyRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     84\u001b[0m _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_request, request)\n\u001b[1;32m     85\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext\u001b[39m.\u001b[39;49msend(request)\n\u001b[1;32m     87\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     88\u001b[0m     _await_result(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_policy\u001b[39m.\u001b[39mon_exception, request)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/_base.py:119\u001b[0m, in \u001b[0;36m_TransportRunner.send\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"HTTP transport send method.\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39m:param request: The PipelineRequest object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39m:rtype: ~azure.core.pipeline.PipelineResponse\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    116\u001b[0m cleanup_kwargs_for_transport(request\u001b[39m.\u001b[39mcontext\u001b[39m.\u001b[39moptions)\n\u001b[1;32m    117\u001b[0m \u001b[39mreturn\u001b[39;00m PipelineResponse(\n\u001b[1;32m    118\u001b[0m     request\u001b[39m.\u001b[39mhttp_request,\n\u001b[0;32m--> 119\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sender\u001b[39m.\u001b[39;49msend(request\u001b[39m.\u001b[39;49mhttp_request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrequest\u001b[39m.\u001b[39;49mcontext\u001b[39m.\u001b[39;49moptions),\n\u001b[1;32m    120\u001b[0m     context\u001b[39m=\u001b[39mrequest\u001b[39m.\u001b[39mcontext,\n\u001b[1;32m    121\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/azure/core/pipeline/transport/_requests_basic.py:381\u001b[0m, in \u001b[0;36mRequestsTransport.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    378\u001b[0m     error \u001b[39m=\u001b[39m ServiceRequestError(err, error\u001b[39m=\u001b[39merr)\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m error:\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mraise\u001b[39;00m error\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m _is_rest(request):\n\u001b[1;32m    383\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mazure\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrest\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_requests_basic\u001b[39;00m \u001b[39mimport\u001b[39;00m RestRequestsTransportResponse\n",
      "\u001b[0;31mServiceRequestError\u001b[0m: Invalid URL \"ai050-search-unai/indexes('recipes-index')?api-version=2023-07-01-Preview\": No scheme supplied. Perhaps you meant https://ai050-search-unai/indexes('recipes-index')?api-version=2023-07-01-Preview?"
     ]
    }
   ],
   "source": [
    "# Create a search index\n",
    "fields = [\n",
    "    SimpleField(name=\"recipe_id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"recipe_category\", type=SearchFieldDataType.String, filterable=True, analyzer_name=\"en.microsoft\"),    \n",
    "    SearchableField(name=\"recipe_name\", type=SearchFieldDataType.String, facetable=True, analyzer_name=\"en.microsoft\"),\n",
    "    SearchableField(name=\"ingredients\", collection=True, type=SearchFieldDataType.String, facetable=True, filterable=True),\n",
    "    SearchableField(name=\"recipe\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "    SearchableField(name=\"description\", type=SearchFieldDataType.String, analyzer_name=\"en.microsoft\"),\n",
    "    SimpleField(name=\"total_time\", type=SearchFieldDataType.Int32, filterable=True, facetable=True),\n",
    "    SearchField(name=\"recipe_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\")\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Semantic Configuration to leverage Bing family of ML models for re-ranking (L2)\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=None,\n",
    "        prioritized_keywords_fields=[],\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"recipe\")]\n",
    "    ))\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields, \n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.delete_index(index)\n",
    "print(f' {index_name} deleted')\n",
    "result = index_client.create_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a helper function to create embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings for title and content fields, also used for query embeddings\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(6))\n",
    "def generate_embeddings(text):\n",
    "    response = openai.Embedding.create(\n",
    "        input=text, engine=\"text-embedding-ada-002\")\n",
    "    embeddings = response['data'][0]['embedding']\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data into Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 100 documents\n",
      "Uploaded 3 documents\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "counter = 0\n",
    "documents = []\n",
    "search_client = SearchClient(endpoint=service_endpoint, index_name=index_name, credential=credential)\n",
    "\n",
    "with open(\"recipes_final.jsonl\", \"r\") as j_in:\n",
    "    for line in j_in:\n",
    "        counter += 1 \n",
    "        json_recipe = json.loads(line)\n",
    "        json_recipe['total_time'] = int(json_recipe['total_time'].split(' ')[0])\n",
    "        json_recipe['recipe_vector'] = generate_embeddings(json_recipe['recipe'])\n",
    "        json_recipe[\"@search.action\"] = \"upload\"\n",
    "        documents.append(json_recipe)\n",
    "        if counter % batch_size == 0:\n",
    "            # Load content into index\n",
    "            result = search_client.upload_documents(documents)  \n",
    "            print(f\"Uploaded {len(documents)} documents\") \n",
    "            documents = []\n",
    "            \n",
    "            \n",
    "if documents != []:\n",
    "    # Load content into index\n",
    "    result = search_client.upload_documents(documents)  \n",
    "    print(f\"Uploaded {len(documents)} documents\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Test function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"function_call\": {\n",
      "    \"name\": \"query_recipes\",\n",
      "    \"arguments\": \"{\\n  \\\"query\\\": \\\"lasagna\\\"\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Help me find a good lasagna recipe.\"}]\n",
    "    \n",
    "# messages = [{\"role\": \"user\", \"content\": \"Help me find a good mexican recipe that has beans and rice\"}]\n",
    "# messages = [{\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}]\n",
    "\n",
    "### Try again with a more detailed system message ###\n",
    "# system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "# You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "# You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "# \"\"\"\n",
    "\n",
    "# messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "#             {\"role\": \"user\", \"content\": \"What should I cook for dinner?\"}]\n",
    "\n",
    "# messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "#            {\"role\": \"user\", \"content\": \"find an easy mexican recipe with beans and rice\"}]\n",
    "                \n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"query_recipes\",\n",
    "        \"description\": \"Retrieve recipes from the Azure Cognitive Search index\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query string to search for recipes\",\n",
    "                },\n",
    "                \"ingredients_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the ingredients field. Only actual ingredient names should be used in this filter. If you're not sure something is an ingredient, don't include this filter. Example: ingredients/any(i: i eq 'salt' or i eq 'pepper')\",\n",
    "                },\n",
    "                \"time_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the total_time field. If a user asks for a quick or easy recipe, you should filter down to recipes that will take less than 30 minutes. Example: total_time lt 25\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    deployment_id=\"gpt-35-turbo-0613\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    temperature=0.2,\n",
    "    function_call=\"auto\", \n",
    ")\n",
    "\n",
    "print(response['choices'][0]['message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to call Azure Cognitive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_recipes(query, ingredients_filter=None, time_filter=None):\n",
    "    filter = \"\"\n",
    "    if ingredients_filter and time_filter:\n",
    "        filter = f\"{time_filter} and {ingredients_filter}\"\n",
    "    elif ingredients_filter:\n",
    "        filter = ingredients_filter\n",
    "    elif time_filter:\n",
    "        filter = time_filter\n",
    "\n",
    "\n",
    "    results = search_client.search(  \n",
    "        query_type=\"semantic\",\n",
    "        query_language=\"en-us\",\n",
    "        semantic_configuration_name=\"my-semantic-config\",\n",
    "        search_text=query,  \n",
    "        vectors=[Vector(value=generate_embeddings(query), k=3, fields=\"recipe_vector\")],\n",
    "        filter=filter,\n",
    "        select=[\"recipe_id\", \"recipe\", \"recipe_category\", \"recipe_name\", \"description\"],\n",
    "        top=3\n",
    "    )  \n",
    "   \n",
    "    n = 1\n",
    "    recipes_for_prompt = \"\"\n",
    "    for result in results:\n",
    "        recipes_for_prompt += f\"Recipe {result['recipe_id']}: {result['recipe_name']}: {result['description']}\\n\"\n",
    "        n += 1\n",
    "\n",
    "    return recipes_for_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Get things running end to end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(messages, functions, available_functions, deployment_id):\n",
    "    \n",
    "    # Step 1: send the conversation and available functions to GPT\n",
    "    response = openai.ChatCompletion.create(\n",
    "        deployment_id=deployment_id,\n",
    "        messages=messages,\n",
    "        functions=functions,\n",
    "        function_call=\"auto\", \n",
    "        temperature=0.2\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "    # Step 2: check if the model wants to call a function\n",
    "    if response_message.get(\"function_call\"):\n",
    "        print(\"Recommended Function call:\")\n",
    "        print(response_message.get(\"function_call\"))\n",
    "        print()\n",
    "        \n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        \n",
    "        # verify function exists\n",
    "        if function_name not in available_functions:\n",
    "            return \"Function \" + function_name + \" does not exist\"\n",
    "        function_to_call = available_functions[function_name]  \n",
    "        \n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = function_to_call(**function_args)\n",
    "        \n",
    "        print(\"Output of function call:\")\n",
    "        print(function_response)\n",
    "        print()\n",
    "        \n",
    "        # Step 4: send the info on the function call and function response to the model\n",
    "        \n",
    "        # adding assistant response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": response_message[\"role\"],\n",
    "                \"function_call\": {\n",
    "                    \"name\": response_message[\"function_call\"][\"name\"],\n",
    "                    \"arguments\": response_message[\"function_call\"][\"arguments\"],\n",
    "                },\n",
    "                \"content\": None\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # adding function response to messages\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            }\n",
    "        )  # extend conversation with function response\n",
    "\n",
    "        print(\"Messages in second request:\")\n",
    "        for message in messages:\n",
    "            print(message)\n",
    "        print()\n",
    "\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "            messages=messages,\n",
    "            deployment_id=deployment_id\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "        return second_response\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"query_recipes\",\n",
      "  \"arguments\": \"{\\n  \\\"query\\\": \\\"pasta\\\",\\n  \\\"time_filter\\\": \\\"total_time lt 60\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "Recipe 46: Pesto Pasta: Pesto Pasta is a classic Italian dish that combines al dente pasta with a flavorful sauce made from fresh basil, garlic, pine nuts, Parmesan cheese, and olive oil. It's a versatile and delicious meal that can be enjoyed as a main dish or as a side.\n",
      "Recipe 76: Tortellini Alfredo: A creamy and delicious pasta dish filled with cheesy tortellini, smothered in a rich alfredo sauce.\n",
      "Recipe 65: Cacio e Pepe: Cacio e Pepe is a classic Roman dish that translates to \"cheese and pepper\". It consists of simple ingredients that when combined, create a delicious and comforting pasta dish with a creamy, cheesy, and peppery sauce.\n",
      "\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'system', 'content': \"Assistant is a large language model designed to help users find and create recipes.\\n\\nYou have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\\n\\nYou are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\\n\"}\n",
      "{'role': 'user', 'content': 'I want to make a pasta dish that takes less than 60 minutes to make.'}\n",
      "{'role': 'assistant', 'function_call': {'name': 'query_recipes', 'arguments': '{\\n  \"query\": \"pasta\",\\n  \"time_filter\": \"total_time lt 60\"\\n}'}, 'content': None}\n",
      "{'role': 'function', 'name': 'query_recipes', 'content': 'Recipe 46: Pesto Pasta: Pesto Pasta is a classic Italian dish that combines al dente pasta with a flavorful sauce made from fresh basil, garlic, pine nuts, Parmesan cheese, and olive oil. It\\'s a versatile and delicious meal that can be enjoyed as a main dish or as a side.\\nRecipe 76: Tortellini Alfredo: A creamy and delicious pasta dish filled with cheesy tortellini, smothered in a rich alfredo sauce.\\nRecipe 65: Cacio e Pepe: Cacio e Pepe is a classic Roman dish that translates to \"cheese and pepper\". It consists of simple ingredients that when combined, create a delicious and comforting pasta dish with a creamy, cheesy, and peppery sauce.\\n'}\n",
      "\n",
      "Final response:\n",
      "Here are some pasta dishes that take less than 60 minutes to make:\n",
      "\n",
      "1. Pesto Pasta: This classic Italian dish combines al dente pasta with a flavorful sauce made from fresh basil, garlic, pine nuts, Parmesan cheese, and olive oil.\n",
      "\n",
      "2. Tortellini Alfredo: A creamy and delicious pasta dish filled with cheesy tortellini, smothered in a rich alfredo sauce.\n",
      "\n",
      "3. Cacio e Pepe: A classic Roman dish that consists of simple ingredients like cheese and pepper. It creates a delicious and comforting pasta dish with a creamy, cheesy, and peppery sauce.\n",
      "\n",
      "Let me know if you'd like the full recipe for any of these dishes or if you have any other questions!\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"I want to make a pasta dish that takes less than 60 minutes to make.\"}]\n",
    "\n",
    "available_functions = {'query_recipes': query_recipes}\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Define additional functions\n",
    "\n",
    "Now that we have the `query_recipes` function defined, we can add additional functions to add more capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"query_recipes\",\n",
    "        \"description\": \"Retrieve recipes from the Azure Cognitive Search index\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The query string to search for recipes\",\n",
    "                },\n",
    "                \"time_filter\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The odata filter to apply for the total_time field. If a user asks for a quick or easy recipe, you should filter down to recipes that will take less than 30 minutes. Example: total_time lt 25\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"],\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"get_recipe\",\n",
    "        \"description\": \"Gets a recipe based on it's id\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The id of a recipe. Usually a number such as 3846\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"id\"],\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"convert_measurement\",\n",
    "        \"description\": \"converts a measurement from one unit to another for common cooking measurements\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"amount\": {\n",
    "                    \"type\": \"number\",\n",
    "                    \"description\": \"The quantity of the measurement to convert.\",\n",
    "                },\n",
    "                \"from_unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unit to convert the measurement from. Supported values are tablespoons, teaspoons, cups, and ounces.\",\n",
    "                },\n",
    "                \"to_unit\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The unit to convert the measurement to. Supported values are tablespoons, teaspoons, cups, and ounces.\",\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"amount\", \"from_unit\", \"to_unit\"],\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to convert common measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3 teaspoons'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_measurement(amount, from_unit, to_unit):\n",
    "    conversions = {\n",
    "        \"tablespoons\": {\n",
    "            \"teaspoons\": 3,\n",
    "            \"cups\": 1/16,\n",
    "            \"ounces\": 1/2.667\n",
    "        },\n",
    "        \"teaspoons\": {\n",
    "            \"tablespoons\": 1/3,\n",
    "            \"cups\": 1/48,\n",
    "            \"ounces\": 1/6\n",
    "        },\n",
    "        \"cups\": {\n",
    "            \"tablespoons\": 16,\n",
    "            \"teaspoons\": 48,\n",
    "            \"ounces\": 8\n",
    "        },\n",
    "        \"ounces\": {\n",
    "            \"tablespoons\": 3,\n",
    "            \"teaspoons\": 6,\n",
    "            \"cups\": 1/8\n",
    "        }\n",
    "    }\n",
    "    if from_unit == to_unit:\n",
    "        return str(amount) + \" \" + to_unit\n",
    "    else:\n",
    "        conversion_factor = conversions[from_unit][to_unit]\n",
    "        converted_amount = amount * conversion_factor\n",
    "        return str(converted_amount) + \" \" + to_unit\n",
    "\n",
    "convert_measurement(1, from_unit=\"tablespoons\", to_unit=\"teaspoons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to get recipes by id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recipe: Malabar Paratha\\n\\nDescription: Malabar Paratha is a popular Indian flatbread known for its flaky and layered texture. It is perfect for serving alongside curries or as a delicious snack on its own.\\n\\nCook Time: 10 minutes\\nPrep Time: 20 minutes\\nTotal Time: 30 minutes\\n\\nIngredients:\\n- 2 cups all-purpose flour\\n- 1/2 teaspoon salt\\n- 1 tablespoon ghee (clarified butter)\\n- 3/4 cup water\\n- Additional ghee for brushing\\n\\nInstructions:\\n1. In a large mixing bowl, combine the all-purpose flour and salt. Mix well.\\n2. Add the ghee to the flour mixture and mix using your fingertips until the mixture resembles breadcrumbs.\\n3. Gradually add water to the mixture while kneading the dough. Continue kneading until a soft and smooth dough is formed. Cover the dough and let it rest for 15 minutes.\\n4. After the dough has rested, divide it into small equal-sized balls, approximately golf ball-sized.\\n5. Take one dough ball and roll it out into a small circle using a rolling pin.\\n6. Brush the surface of the rolled dough with ghee.\\n7. Starting from one end, tightly roll the dough into a cylinder shape.\\n8. Once rolled, coil the cylinder into a spiral shape.\\n9. Flatten the spiral-shaped dough using a rolling pin to make a circular shaped paratha.\\n10. Heat a tawa or flat pan over medium heat. Place the flattened paratha onto the pan and cook for about 1-2 minutes, or until golden brown spots start to appear.\\n11. Flip the paratha and brush the cooked side with ghee. Cook for another 1-2 minutes, or until golden brown spots appear on the other side as well.\\n12. Remove the paratha from the pan and place it on a serving plate. Repeat the process for the remaining dough balls.\\n13. Serve the Malabar Parathas hot with your favorite curry or enjoy them on their own.\\n\\nEnjoy your delicious homemade Malabar Parathas!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recipe(id):\n",
    "    return search_client.get_document(key=id)['recipe']\n",
    "\n",
    "get_recipe(\"151\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.0 Test more examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {'query_recipes': query_recipes, \n",
    "                       'get_recipe': get_recipe,    \n",
    "                       'convert_measurement': convert_measurement}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Function call:\n",
      "{\n",
      "  \"name\": \"convert_measurement\",\n",
      "  \"arguments\": \"{\\n  \\\"amount\\\": 2,\\n  \\\"from_unit\\\": \\\"tablespoons\\\",\\n  \\\"to_unit\\\": \\\"cups\\\"\\n}\"\n",
      "}\n",
      "\n",
      "Output of function call:\n",
      "0.125 cups\n",
      "\n",
      "Messages in second request:\n",
      "{'role': 'system', 'content': \"Assistant is a large language model designed to help users find and create recipes.\\n\\nYou have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\\n\\nYou are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\\n\"}\n",
      "{'role': 'user', 'content': 'How many cups is 2 tablespoons of butter?'}\n",
      "{'role': 'assistant', 'function_call': {'name': 'convert_measurement', 'arguments': '{\\n  \"amount\": 2,\\n  \"from_unit\": \"tablespoons\",\\n  \"to_unit\": \"cups\"\\n}'}, 'content': None}\n",
      "{'role': 'function', 'name': 'convert_measurement', 'content': '0.125 cups'}\n",
      "\n",
      "Final response:\n",
      "2 tablespoons of butter is equal to 0.125 cups.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": \"How many cups is 2 tablespoons of butter?\"}]\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"Assistant is a large language model designed to help users find and create recipes.\n",
    "\n",
    "You have access to an Azure Cognitive Search index with hundreds of recipes. You can search for recipes by name, ingredient, or cuisine.\n",
    "\n",
    "You are designed to be an interactive assistant, so you can ask users clarifying questions to help them find the right recipe. It's better to give more detailed queries to the search index rather than vague one.\n",
    "\"\"\"\n",
    "\n",
    "messages = [{'role': 'system', 'content': system_message},\n",
    "            {'role': 'user', 'content': 'Help me find a Thai recipe I can cook in less than an hour'},\n",
    "            {'role': 'assistant', 'function_call': {'name': 'query_recipes', 'arguments': '{\\n  \"query\": \"Thai\",\\n  \"time_filter\": \"total_time lt 60\"\\n}'}, 'content': None},\n",
    "            {'role': 'function', 'name': 'query_recipes', 'content': \"Recipe 200: Thai Peanut Noodles: Thai Peanut Noodles is a delicious and flavorful dish that combines the creaminess of peanut butter with the tanginess of lime and the heat of chili. This dish is perfect for those who enjoy a balance of sweet, savory, and spicy flavors.\\nRecipe 206: Thai Cashew Tofu Stir-Fry: This Thai-inspired stir-fry is packed with flavor, combining crispy tofu, crunchy vegetables, and cashews in a savory sauce. It's a quick and delicious weeknight meal option.\\nRecipe 196: Thai Beef Salad: Thai Beef Salad is a refreshing and vibrant dish that combines tender beef with a tangy and spicy dressing, fresh herbs, and colorful vegetables.\\n\"},\n",
    "            {'role': 'assistant', 'content': \"Here are a few Thai recipes that you can cook in less than an hour:\\n\\n1. Thai Peanut Noodles: This dish combines the creaminess of peanut butter with the tanginess of lime and the heat of chili. It's a perfect balance of sweet, savory, and spicy flavors.\\n\\n2. Thai Cashew Tofu Stir-Fry: This stir-fry is packed with flavor, combining crispy tofu, crunchy vegetables, and cashews in a savory sauce. It's a quick and delicious option for a weeknight meal.\\n\\n3. Thai Beef Salad: This refreshing and vibrant salad combines tender beef with a tangy and spicy dressing, fresh herbs, and colorful vegetables.\\n\\nLet me know if you'd like more information about any of these recipes!\"},\n",
    "            {'role': 'user', 'content': 'Show me the thai peanut noodles recipe'}\n",
    "]\n",
    "\n",
    "result = run_conversation(messages, functions, available_functions, deployment_name)\n",
    "\n",
    "print(\"Final response:\")\n",
    "print(result['choices'][0]['message'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
